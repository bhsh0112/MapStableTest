#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NuScenes Token to Image è½¬æ¢å·¥å…·

è¯¥è„šæœ¬ç”¨äºæ ¹æ®NuScenesæ•°æ®é›†çš„tokenè¾“å‡ºå¯¹åº”çš„è¾“å…¥å›¾åƒï¼ŒåŒ…æ‹¬ï¼š
- å¤šç›¸æœºå›¾åƒï¼ˆ6ä¸ªè§†è§’ï¼‰
- æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®
- è‡ªè½¦ä½ç½®å’Œå§¿æ€ä¿¡æ¯
- åœ°å›¾ä¿¡æ¯

ä½œè€…: AI Assistant
æ—¥æœŸ: 2024
"""

import os
import sys
import argparse
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import cv2
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import json

# NuScenesç›¸å…³å¯¼å…¥
from nuscenes.nuscenes import NuScenes
from nuscenes.map_expansion.map_api import NuScenesMap
from nuscenes.utils.data_classes import LidarPointCloud, Box
from nuscenes.utils.geometry_utils import view_points, transform_matrix
from pyquaternion import Quaternion


class NuScenesTokenToImage:
    """
    NuScenes Tokenåˆ°å›¾åƒè½¬æ¢å™¨
    
    è¯¥ç±»æä¾›äº†ä»NuScenesæ•°æ®é›†çš„tokenæå–å’Œå¯è§†åŒ–å„ç§è¾“å…¥æ•°æ®çš„åŠŸèƒ½
    """
    
    def __init__(self, dataroot: str, version: str = 'v1.0-mini', verbose: bool = True):
        """
        åˆå§‹åŒ–NuScenesæ•°æ®é›†
        
        Args:
            dataroot: NuScenesæ•°æ®é›†æ ¹ç›®å½•è·¯å¾„
            version: æ•°æ®é›†ç‰ˆæœ¬ (v1.0-mini, v1.0-trainval, v1.0-test)
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
        self.dataroot = dataroot
        self.version = version
        self.verbose = verbose
        
        # åˆå§‹åŒ–NuSceneså®ä¾‹
        try:
            self.nusc = NuScenes(version=version, dataroot=dataroot, verbose=verbose)
            print(f"âœ… æˆåŠŸåŠ è½½NuScenesæ•°æ®é›†: {version}")
        except Exception as e:
            print(f"âŒ åŠ è½½NuScenesæ•°æ®é›†å¤±è´¥: {e}")
            sys.exit(1)
        
        # ç›¸æœºé…ç½®
        self.camera_names = [
            'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_RIGHT',
            'CAM_BACK', 'CAM_BACK_LEFT', 'CAM_FRONT_LEFT'
        ]
        
        # é¢œè‰²é…ç½®
        self.colors = {
            'CAM_FRONT': 'red',
            'CAM_FRONT_RIGHT': 'orange', 
            'CAM_BACK_RIGHT': 'yellow',
            'CAM_BACK': 'green',
            'CAM_BACK_LEFT': 'blue',
            'CAM_FRONT_LEFT': 'purple'
        }
    
    def get_sample_info(self, sample_token: str) -> Dict:
        """
        è·å–sampleçš„åŸºæœ¬ä¿¡æ¯
        
        Args:
            sample_token: sampleçš„token
            
        Returns:
            åŒ…å«sampleä¿¡æ¯çš„å­—å…¸
        """
        try:
            sample = self.nusc.get('sample', sample_token)
            
            # è·å–åœºæ™¯ä¿¡æ¯
            scene = self.nusc.get('scene', sample['scene_token'])
            log = self.nusc.get('log', scene['log_token'])
            
            info = {
                'sample_token': sample_token,
                'scene_token': sample['scene_token'],
                'timestamp': sample['timestamp'],
                'scene_name': scene['name'],
                'location': log['location'],
                'weather': log['weather'],
                'camera_data': {},
                'lidar_data': None,
                'ego_pose': None
            }
            
            return info
            
        except Exception as e:
            print(f"âŒ è·å–sampleä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def extract_camera_images(self, sample_token: str, save_dir: Optional[str] = None) -> Dict[str, np.ndarray]:
        """
        æå–æŒ‡å®šsampleçš„æ‰€æœ‰ç›¸æœºå›¾åƒ
        
        Args:
            sample_token: sampleçš„token
            save_dir: å›¾åƒä¿å­˜ç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä¸ä¿å­˜
            
        Returns:
            åŒ…å«æ‰€æœ‰ç›¸æœºå›¾åƒçš„å­—å…¸
        """
        try:
            sample = self.nusc.get('sample', sample_token)
            images = {}
            
            if save_dir:
                os.makedirs(save_dir, exist_ok=True)
            
            for camera_name in self.camera_names:
                # è·å–ç›¸æœºæ•°æ®token
                camera_token = sample['data'][camera_name]
                camera_data = self.nusc.get('sample_data', camera_token)
                
                # æ„å»ºå›¾åƒè·¯å¾„
                image_path = os.path.join(self.dataroot, camera_data['filename'])
                
                # è¯»å–å›¾åƒ
                if os.path.exists(image_path):
                    image = cv2.imread(image_path)
                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                    images[camera_name] = image
                    
                    # ä¿å­˜å›¾åƒ
                    if save_dir:
                        save_path = os.path.join(save_dir, f"{camera_name}_{sample_token[:8]}.jpg")
                        cv2.imwrite(save_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
                        print(f"ğŸ“· ä¿å­˜ç›¸æœºå›¾åƒ: {save_path}")
                else:
                    print(f"âš ï¸  å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            
            return images
            
        except Exception as e:
            print(f"âŒ æå–ç›¸æœºå›¾åƒå¤±è´¥: {e}")
            return {}
    
    def extract_lidar_data(self, sample_token: str, save_dir: Optional[str] = None) -> Optional[np.ndarray]:
        """
        æå–æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®
        
        Args:
            sample_token: sampleçš„token
            save_dir: ç‚¹äº‘ä¿å­˜ç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä¸ä¿å­˜
            
        Returns:
            ç‚¹äº‘æ•°æ®æ•°ç»„ (N, 4) [x, y, z, intensity]
        """
        try:
            sample = self.nusc.get('sample', sample_token)
            
            # è·å–æ¿€å…‰é›·è¾¾æ•°æ®token
            lidar_token = sample['data']['LIDAR_TOP']
            lidar_data = self.nusc.get('sample_data', lidar_token)
            
            # æ„å»ºç‚¹äº‘æ–‡ä»¶è·¯å¾„
            pc_path = os.path.join(self.dataroot, lidar_data['filename'])
            
            if os.path.exists(pc_path):
                # è¯»å–ç‚¹äº‘æ•°æ®
                pc = LidarPointCloud.from_file(pc_path)
                points = pc.points.T  # è½¬æ¢ä¸º (N, 4) æ ¼å¼
                
                # ä¿å­˜ç‚¹äº‘æ•°æ®
                if save_dir:
                    os.makedirs(save_dir, exist_ok=True)
                    save_path = os.path.join(save_dir, f"lidar_{sample_token[:8]}.npy")
                    np.save(save_path, points)
                    print(f"ğŸ” ä¿å­˜æ¿€å…‰é›·è¾¾æ•°æ®: {save_path}")
                
                return points
            else:
                print(f"âš ï¸  ç‚¹äº‘æ–‡ä»¶ä¸å­˜åœ¨: {pc_path}")
                return None
                
        except Exception as e:
            print(f"âŒ æå–æ¿€å…‰é›·è¾¾æ•°æ®å¤±è´¥: {e}")
            return None
    
    def get_ego_pose(self, sample_token: str) -> Optional[Dict]:
        """
        è·å–è‡ªè½¦ä½ç½®å’Œå§¿æ€ä¿¡æ¯
        
        Args:
            sample_token: sampleçš„token
            
        Returns:
            åŒ…å«è‡ªè½¦ä½å§¿ä¿¡æ¯çš„å­—å…¸
        """
        try:
            sample = self.nusc.get('sample', sample_token)
            lidar_token = sample['data']['LIDAR_TOP']
            lidar_data = self.nusc.get('sample_data', lidar_token)
            ego_pose = self.nusc.get('ego_pose', lidar_data['ego_pose_token'])
            
            # æå–ä½ç½®å’Œæ—‹è½¬ä¿¡æ¯
            translation = ego_pose['translation']
            rotation = ego_pose['rotation']
            
            # å°†å››å…ƒæ•°è½¬æ¢ä¸ºæ¬§æ‹‰è§’
            q = Quaternion(rotation)
            yaw, pitch, roll = q.yaw_pitch_roll
            
            pose_info = {
                'translation': translation,
                'rotation_quat': rotation,
                'yaw': yaw,
                'pitch': pitch,
                'roll': roll,
                'timestamp': ego_pose['timestamp']
            }
            
            return pose_info
            
        except Exception as e:
            print(f"âŒ è·å–è‡ªè½¦ä½å§¿å¤±è´¥: {e}")
            return None
    
    def visualize_camera_images(self, images: Dict[str, np.ndarray], sample_token: str, 
                              save_path: Optional[str] = None) -> None:
        """
        å¯è§†åŒ–æ‰€æœ‰ç›¸æœºå›¾åƒ
        
        Args:
            images: ç›¸æœºå›¾åƒå­—å…¸
            sample_token: sampleçš„token
            save_path: å¯è§†åŒ–ç»“æœä¿å­˜è·¯å¾„
        """
        if not images:
            print("âš ï¸  æ²¡æœ‰å¯å¯è§†åŒ–çš„å›¾åƒ")
            return
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        for i, (camera_name, image) in enumerate(images.items()):
            if i < len(axes):
                axes[i].imshow(image)
                axes[i].set_title(f'{camera_name}\nToken: {sample_token[:8]}...', 
                                color=self.colors.get(camera_name, 'black'))
                axes[i].axis('off')
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(images), len(axes)):
            axes[i].axis('off')
        
        plt.suptitle(f'NuScenes Sample Images - Token: {sample_token}', fontsize=16)
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"ğŸ–¼ï¸  ä¿å­˜å¯è§†åŒ–å›¾åƒ: {save_path}")
        
        plt.show()
    
    def visualize_lidar_points(self, points: np.ndarray, sample_token: str, 
                             save_path: Optional[str] = None) -> None:
        """
        å¯è§†åŒ–æ¿€å…‰é›·è¾¾ç‚¹äº‘ï¼ˆä¿¯è§†å›¾ï¼‰
        
        Args:
            points: ç‚¹äº‘æ•°æ® (N, 4)
            sample_token: sampleçš„token
            save_path: å¯è§†åŒ–ç»“æœä¿å­˜è·¯å¾„
        """
        if points is None or len(points) == 0:
            print("âš ï¸  æ²¡æœ‰å¯å¯è§†åŒ–çš„ç‚¹äº‘æ•°æ®")
            return
        
        # åˆ›å»ºä¿¯è§†å›¾
        fig, ax = plt.subplots(1, 1, figsize=(12, 12))
        
        # ç»˜åˆ¶ç‚¹äº‘ï¼ˆä½¿ç”¨å¼ºåº¦ä½œä¸ºé¢œè‰²ï¼‰
        scatter = ax.scatter(points[:, 0], points[:, 1], 
                           c=points[:, 3], cmap='viridis', s=0.5, alpha=0.6)
        
        ax.set_xlabel('X (m)')
        ax.set_ylabel('Y (m)')
        ax.set_title(f'LiDAR Point Cloud - Token: {sample_token[:8]}...')
        ax.grid(True, alpha=0.3)
        ax.set_aspect('equal')
        
        # æ·»åŠ é¢œè‰²æ¡
        plt.colorbar(scatter, ax=ax, label='Intensity')
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"ğŸ” ä¿å­˜ç‚¹äº‘å¯è§†åŒ–: {save_path}")
        
        plt.show()
    
    def process_token(self, sample_token: str, output_dir: str = "./output") -> Dict:
        """
        å¤„ç†æŒ‡å®šçš„tokenï¼Œæå–æ‰€æœ‰ç›¸å…³æ•°æ®
        
        Args:
            sample_token: sampleçš„token
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            åŒ…å«æ‰€æœ‰æå–æ•°æ®çš„å­—å…¸
        """
        print(f"ğŸš€ å¼€å§‹å¤„ç†token: {sample_token}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # è·å–sampleåŸºæœ¬ä¿¡æ¯
        sample_info = self.get_sample_info(sample_token)
        if not sample_info:
            return {}
        
        print(f"ğŸ“ åœºæ™¯: {sample_info['scene_name']}")
        print(f"ğŸŒ ä½ç½®: {sample_info['location']}")
        print(f"ğŸŒ¤ï¸  å¤©æ°”: {sample_info['weather']}")
        
        # æå–ç›¸æœºå›¾åƒ
        print("ğŸ“· æå–ç›¸æœºå›¾åƒ...")
        images = self.extract_camera_images(sample_token, 
                                          os.path.join(output_dir, "camera_images"))
        
        # æå–æ¿€å…‰é›·è¾¾æ•°æ®
        print("ğŸ” æå–æ¿€å…‰é›·è¾¾æ•°æ®...")
        lidar_points = self.extract_lidar_data(sample_token, 
                                             os.path.join(output_dir, "lidar_data"))
        
        # è·å–è‡ªè½¦ä½å§¿
        print("ğŸš— è·å–è‡ªè½¦ä½å§¿...")
        ego_pose = self.get_ego_pose(sample_token)
        
        # å¯è§†åŒ–ç›¸æœºå›¾åƒ
        if images:
            camera_viz_path = os.path.join(output_dir, f"camera_visualization_{sample_token[:8]}.png")
            self.visualize_camera_images(images, sample_token, camera_viz_path)
        
        # å¯è§†åŒ–æ¿€å…‰é›·è¾¾ç‚¹äº‘
        if lidar_points is not None:
            lidar_viz_path = os.path.join(output_dir, f"lidar_visualization_{sample_token[:8]}.png")
            self.visualize_lidar_points(lidar_points, sample_token, lidar_viz_path)
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            'sample_token': sample_token,
            'sample_info': sample_info,
            'ego_pose': ego_pose,
            'num_cameras': len(images),
            'num_lidar_points': len(lidar_points) if lidar_points is not None else 0,
            'camera_names': list(images.keys()),
            'output_directory': output_dir
        }
        
        metadata_path = os.path.join(output_dir, f"metadata_{sample_token[:8]}.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ ä¿å­˜å…ƒæ•°æ®: {metadata_path}")
        print(f"âœ… å¤„ç†å®Œæˆï¼è¾“å‡ºç›®å½•: {output_dir}")
        
        return metadata


def main():
    """
    ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£
    """
    parser = argparse.ArgumentParser(description='NuScenes Tokenåˆ°å›¾åƒè½¬æ¢å·¥å…·')
    parser.add_argument('--token', type=str, required=True, 
                       help='NuScenes sample token')
    parser.add_argument('--dataroot', type=str, required=True,
                       help='NuScenesæ•°æ®é›†æ ¹ç›®å½•è·¯å¾„')
    parser.add_argument('--version', type=str, default='v1.0-mini',
                       choices=['v1.0-mini', 'v1.0-trainval', 'v1.0-test'],
                       help='NuScenesæ•°æ®é›†ç‰ˆæœ¬')
    parser.add_argument('--output', type=str, default='./output',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--no-visualize', action='store_true',
                       help='ä¸æ˜¾ç¤ºå¯è§†åŒ–å›¾åƒ')
    
    args = parser.parse_args()
    
    # éªŒè¯è¾“å…¥
    if not os.path.exists(args.dataroot):
        print(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {args.dataroot}")
        sys.exit(1)
    
    # åˆ›å»ºè½¬æ¢å™¨å®ä¾‹
    converter = NuScenesTokenToImage(
        dataroot=args.dataroot,
        version=args.version,
        verbose=True
    )
    
    # å¤„ç†token
    try:
        result = converter.process_token(args.token, args.output)
        
        if result:
            print("\nğŸ“Š å¤„ç†ç»“æœæ‘˜è¦:")
            print(f"   Token: {result['sample_token']}")
            print(f"   ç›¸æœºæ•°é‡: {result['num_cameras']}")
            print(f"   ç‚¹äº‘æ•°é‡: {result['num_lidar_points']}")
            print(f"   è¾“å‡ºç›®å½•: {result['output_directory']}")
        else:
            print("âŒ å¤„ç†å¤±è´¥")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(0)
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    # å¦‚æœç›´æ¥è¿è¡Œè„šæœ¬ï¼Œä½¿ç”¨å‘½ä»¤è¡Œæ¥å£
    if len(sys.argv) > 1:
        main()
    else:
        # äº¤äº’å¼ä½¿ç”¨ç¤ºä¾‹
        print("ğŸ”§ NuScenes Tokenåˆ°å›¾åƒè½¬æ¢å·¥å…·")
        print("=" * 50)
        
        # é…ç½®å‚æ•°ï¼ˆè¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
        DATAROOT = "/path/to/nuscenes"  # è¯·ä¿®æ”¹ä¸ºå®é™…çš„æ•°æ®é›†è·¯å¾„
        VERSION = "v1.0-mini"
        SAMPLE_TOKEN = "0a0d6b8c2e884134a3b48df43d54c36a"  # ç¤ºä¾‹token
        
        print(f"ğŸ“ æ•°æ®é›†è·¯å¾„: {DATAROOT}")
        print(f"ğŸ“‹ æ•°æ®é›†ç‰ˆæœ¬: {VERSION}")
        print(f"ğŸ”‘ ç¤ºä¾‹Token: {SAMPLE_TOKEN}")
        print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print("   python token2image.py --token <TOKEN> --dataroot <PATH> --version <VERSION>")
        print("\nğŸ“– æˆ–è€…ä¿®æ”¹è„šæœ¬ä¸­çš„é…ç½®å‚æ•°åç›´æ¥è¿è¡Œ")
